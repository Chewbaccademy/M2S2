{"cells":[{"cell_type":"markdown","metadata":{"id":"R2Xe1KpWgMHs"},"source":["# **DEEP LEARNING**\n","\n","Name: **EXERCICE**  \n","Date : 2023  \n","Author: Aurélien Vannieuwenhuyze  \n","\n","\n","<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Licence Creative Commons\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br />This work is licensed under the terms of the <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.</a>.\n","<hr/>"]},{"cell_type":"markdown","metadata":{"id":"RtDB9M8T_7eY"},"source":["## Cas pratique sonar"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"bZmIUpl7EdWK"},"outputs":[],"source":["import numpy as np\n","import os\n","import pandas as pnd\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score, train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_16 (Dense)            (None, 24)                1464      \n","                                                                 \n"," dense_17 (Dense)            (None, 2)                 50        \n","                                                                 \n","=================================================================\n","Total params: 1,514\n","Trainable params: 1,514\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow import keras\n","\n","keras_model = keras.Sequential()\n","keras_model.add(keras.layers.Input((60,)))\n","keras_model.add(keras.layers.Dense(24, activation='softmax', use_bias=True))\n","keras_model.add(keras.layers.Dense(2, activation='softmax', use_bias=True))\n","\n","keras_model.compile(loss=keras.losses.binary_crossentropy)\n","\n","keras_model.summary()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["          0       1       2       3       4       5       6       7       8  \\\n","61   0.0086  0.0215  0.0242  0.0445  0.0667  0.0771  0.0499  0.0906  0.1229   \n","84   0.0365  0.1632  0.1636  0.1421  0.1130  0.1306  0.2112  0.2268  0.2992   \n","153  0.0117  0.0069  0.0279  0.0583  0.0915  0.1267  0.1577  0.1927  0.2361   \n","48   0.0119  0.0582  0.0623  0.0600  0.1397  0.1883  0.1422  0.1447  0.0487   \n","6    0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n","..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n","200  0.0335  0.0258  0.0398  0.0570  0.0529  0.1091  0.1709  0.1684  0.1865   \n","101  0.0587  0.1210  0.1268  0.1498  0.1436  0.0561  0.0832  0.0672  0.1372   \n","189  0.0156  0.0210  0.0282  0.0596  0.0462  0.0779  0.1365  0.0780  0.1038   \n","182  0.0096  0.0404  0.0682  0.0688  0.0887  0.0932  0.0955  0.2140  0.2546   \n","55   0.0152  0.0102  0.0113  0.0263  0.0097  0.0391  0.0857  0.0915  0.0949   \n","\n","          9  ...      50      51      52      53      54      55      56  \\\n","61   0.1185  ...  0.0047  0.0072  0.0054  0.0022  0.0016  0.0029  0.0058   \n","84   0.3735  ...  0.0223  0.0110  0.0071  0.0205  0.0164  0.0063  0.0078   \n","153  0.2169  ...  0.0039  0.0053  0.0029  0.0020  0.0013  0.0029  0.0020   \n","48   0.0864  ...  0.0069  0.0025  0.0103  0.0074  0.0123  0.0069  0.0076   \n","6    0.2838  ...  0.0052  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085   \n","..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n","200  0.2660  ...  0.0130  0.0120  0.0039  0.0053  0.0062  0.0046  0.0045   \n","101  0.2352  ...  0.0215  0.0331  0.0111  0.0088  0.0158  0.0122  0.0038   \n","189  0.1567  ...  0.0189  0.0150  0.0060  0.0082  0.0091  0.0038  0.0056   \n","182  0.2952  ...  0.0310  0.0237  0.0078  0.0144  0.0170  0.0012  0.0109   \n","55   0.1504  ...  0.0048  0.0049  0.0041  0.0036  0.0013  0.0046  0.0037   \n","\n","         57      58      59  \n","61   0.0050  0.0024  0.0030  \n","84   0.0094  0.0110  0.0068  \n","153  0.0062  0.0026  0.0052  \n","48   0.0073  0.0030  0.0138  \n","6    0.0047  0.0048  0.0053  \n","..      ...     ...     ...  \n","200  0.0022  0.0005  0.0031  \n","101  0.0101  0.0228  0.0124  \n","189  0.0056  0.0048  0.0024  \n","182  0.0036  0.0043  0.0018  \n","55   0.0011  0.0034  0.0033  \n","\n","[103 rows x 60 columns]\n","==============================\n","          0       1       2       3       4       5       6       7       8  \\\n","35   0.0094  0.0166  0.0398  0.0359  0.0681  0.0706  0.1020  0.0893  0.0381   \n","25   0.0151  0.0320  0.0599  0.1050  0.1163  0.1734  0.1679  0.1119  0.0889   \n","97   0.1313  0.2339  0.3059  0.4264  0.4010  0.1791  0.1853  0.0055  0.1929   \n","26   0.0177  0.0300  0.0288  0.0394  0.0630  0.0526  0.0688  0.0633  0.0624   \n","38   0.0091  0.0213  0.0206  0.0505  0.0657  0.0795  0.0970  0.0872  0.0743   \n","..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n","33   0.0311  0.0491  0.0692  0.0831  0.0079  0.0200  0.0981  0.1016  0.2025   \n","93   0.0025  0.0309  0.0171  0.0228  0.0434  0.1224  0.1947  0.1661  0.1368   \n","22   0.0115  0.0150  0.0136  0.0076  0.0211  0.1058  0.1023  0.0440  0.0931   \n","159  0.0258  0.0433  0.0547  0.0681  0.0784  0.1250  0.1296  0.1729  0.2794   \n","172  0.0329  0.0216  0.0386  0.0627  0.1158  0.1482  0.2054  0.1605  0.2532   \n","\n","          9  ...      50      51      52      53      54      55      56  \\\n","35   0.1328  ...  0.0134  0.0141  0.0191  0.0145  0.0065  0.0129  0.0217   \n","25   0.1205  ...  0.0086  0.0061  0.0015  0.0084  0.0128  0.0054  0.0011   \n","97   0.2231  ...  0.0156  0.0362  0.0210  0.0154  0.0180  0.0013  0.0106   \n","26   0.0613  ...  0.0168  0.0102  0.0122  0.0044  0.0075  0.0124  0.0099   \n","38   0.0837  ...  0.0300  0.0112  0.0112  0.0102  0.0026  0.0097  0.0098   \n","..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n","33   0.0767  ...  0.0089  0.0087  0.0032  0.0130  0.0188  0.0101  0.0229   \n","93   0.1430  ...  0.0108  0.0149  0.0077  0.0036  0.0114  0.0085  0.0101   \n","22   0.0734  ...  0.0107  0.0091  0.0016  0.0084  0.0064  0.0026  0.0029   \n","159  0.2954  ...  0.0121  0.0091  0.0062  0.0019  0.0045  0.0079  0.0031   \n","172  0.2672  ...  0.0104  0.0095  0.0151  0.0059  0.0015  0.0053  0.0016   \n","\n","         57      58      59  \n","35   0.0087  0.0077  0.0122  \n","25   0.0019  0.0023  0.0062  \n","97   0.0127  0.0178  0.0231  \n","26   0.0057  0.0032  0.0019  \n","38   0.0043  0.0071  0.0108  \n","..      ...     ...     ...  \n","33   0.0182  0.0046  0.0038  \n","93   0.0016  0.0028  0.0014  \n","22   0.0037  0.0070  0.0041  \n","159  0.0063  0.0048  0.0050  \n","172  0.0042  0.0053  0.0074  \n","\n","[104 rows x 60 columns]\n","==============================\n","[[0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]]\n","==============================\n","[[0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [1]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]\n"," [0]\n"," [0]\n"," [0]\n"," [1]\n"," [1]]\n"]}],"source":["data = pnd.read_csv(\"./sonar.all-data\")\n","\n","input_data = data.sample(frac=1).reset_index(drop=True)"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["class analyseEpoque(keras.callbacks.Callback):\n","    def __init__(self, x_test, y_test):\n","        self.x_test = x_test\n","        self.y_test = y_test\n","        \n","    def on_epoch_end(self, epoch, logs=None):\n","        print(self.x_test)\n","        print(self.y_test)\n","        y_pred = self.model.predict(self.x_test)\n","        print('Prédiction: {} a epoque: {}'.format(y_pred, epoch))\n","        print('Attendu: {} a epoque: {}'.format(self.y_test, epoch))"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"ename":"ValueError","evalue":"in user code:\n\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m keras_model\u001b[39m.\u001b[39;49mfit(X_train, Y_train,  epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,callbacks\u001b[39m=\u001b[39;49m[analyseEpoque(X_train,Y_train)])\n","File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/tmp/__autograph_generated_file8w0deaay.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/home/kilian/.local/lib/python3.10/site-packages/keras/backend.py\", line 5680, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 2) vs (None, 1)).\n"]}],"source":["keras_model.fit(X_train, Y_train,  epochs=10,callbacks=[analyseEpoque(X_train,Y_train)])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4/4 [==============================] - 0s 1ms/step\n","[(1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 0), (1, 0), (1, 1), (1, 0), (1, 1), (1, 0), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1)] 0.47115384615384615\n"]}],"source":["predictions = keras_model.predict(X_test)\n","\n","predictions = [int(pred[1] + pred[0] / 2 > 0.5) for pred in predictions]\n","\n","comparatif = [(predictions[i], Y_test.iloc[i]) for i in range(len(predictions))]\n","tx_erreur = sum([comp[0] - comp[1] for comp in comparatif]) / len(comparatif)\n","\n","print(comparatif, tx_erreur)"]},{"cell_type":"markdown","metadata":{"id":"svweYwckH2Pu"},"source":["Pdf de l'étude (1988):  \n","https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.299.8959&rep=rep1&type=pdf"]},{"cell_type":"markdown","metadata":{"id":"aB7NQy5jAAOy"},"source":["## Chargement du dataset"]},{"cell_type":"markdown","metadata":{"id":"YtrTMs8ErLJS"},"source":["http://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Sonar%2C+Mines+vs.+Rocks%29"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPryZP3eVIFbhYTq0VZhmq8","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":0}
